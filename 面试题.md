# 1.整体思路

## 1.1 自身问题

1.你有什么优势

我看到了贵公司的岗位要求，里面用到的主要技术我都有着实际的相关开发经验

2.你在项目过程中遇到过什么问题，怎么解决的

## 1.2 组件框架原理层面

2（整体）+1（离线）+1（实时）

### 1 组件基础原理层面

hdfs、yarn、hbase、kafka、hive等

为什么可以使用？

### 2 计算框架计算流程层面

spark、flink、mapreduce 计算流程 编程模型等

定位调优，编程扩展

## 1.3 开发调优层面

### 1针对hive、spark、flink计算框架调优

数据倾斜、计算效率、shuffle、参数调优等

### 2代码层级开发层面

SQL场景开发、算子使用和性能、java开发性能

## 1.4 基础理论层面

### 1数仓建设

数据集成、分层、建模、主题等

### 2数据治理方面

数据质量、元数据管理、资产管理等

## 1.5 项目场景价值方面

### 1 业务体系

基于背景？实现价值？

### 2.架构流程

整体流程、参与流程

### 3.团队成员

分工、工作流程

### 4.工作细节

数据量、表多少、指标、遇到问题、反向思考

## 1.6 项目使用

![image-20231203215737589](C:\Users\90809\AppData\Roaming\Typora\typora-user-images\image-20231203215737589.png) 

# 2. Hadoop

## 2.1 HDFS架构原理

HDFS采用master/slave架构，一个HDFS集群包含一个单独的NameNode和多个DateNode。NameNode作为master，他负责管理文件系统的命名空间，维护者文件系统树和整棵树内的文件和目录（元数据）。DataNode是真正存放数据的节点，将存储划分为多个block块，管理block块信息。当DataNode启动时，将扫描其本地文件系统生成所有HDFS数据块的列表，并将其发送到NameNode

HDFS架构下主要有以下角色：Client、NameNode、SecondaryNameNode、DataNode

NameNode的本地持久化

- 命名空间镜像文件（fsimage）
- 编辑日志（edits log）

fsimage存储元数据，edits log 记录用户对文件的若干操作，若NameNode所在节点重启，则需要很长时间执行edits log和更新fsimage，此期间整个系统不可用。

给出的解决方案为SecondaryNameNode

1. SecondaryNameNode通知NameNode准备一份edits文件
2. 把NameNode上的fsimage和edits log 发送一份到SecondaryNameNode上
3. SecondaryNameNode合并fsimage文件和edits，产生一个新的文件fsimage.ckpt写入磁盘
4. SecondaryNameNode将fsimage发送到NameNode
5. NameNode将fsimage.ckpt文件重命名并准备使用

该方案相当于使用SecondaryNameNode按一定时长对NameNode中的fsimage和edits log进行周期性的合并，如果发生意外NameNode重启，fsimage需要执行的edits操作就会比较少。

dfs.namenode.checkpoint.period设置多久进行一次checkpoint合并，单位秒，默认1小时

由dfs.namenode.checkpoint.txns设置事务数量，默认1000000个

dfs.namenode.checkpoint.check.period设置事务数量检查时间，单位秒，默认1分钟

# ***算法题

## 1. 海量数据Top N类

### 1.1  海量数据找出不重复/重复的数，使用位图

### 1.2 海量数据 找出topN

可以使用优先队列（最小堆），N个数据组成初始优先队列，每读取一个数据，与最小数据进行比较，大的入队，小的出队
